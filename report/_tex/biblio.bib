
@article{chatzopoulos_mobile_2017,
	title = {Mobile {Augmented} {Reality} {Survey}: {From} {Where} {We} {Are} to {Where} {We} {Go}},
	volume = {5},
	issn = {2169-3536},
	shorttitle = {Mobile {Augmented} {Reality} {Survey}},
	url = {http://ieeexplore.ieee.org/document/7912316/},
	doi = {10.1109/ACCESS.2017.2698164},
	abstract = {The boom in the capabilities and features of mobile devices, like smartphones, tablets, and wearables, combined with the ubiquitous and affordable Internet access and the advances in the areas of cooperative networking, computer vision, and mobile cloud computing transformed mobile augmented reality (MAR) from science ﬁction to a reality. Although mobile devices are more constrained computationalwise from traditional computers, they have a multitude of sensors that can be used to the development of more sophisticated MAR applications and can be assisted from remote servers for the execution of their intensive parts. In this paper, after introducing the reader to the basics of MAR, we present a categorization of the application ﬁelds together with some representative examples. Next, we introduce the reader to the user interface and experience in MAR applications and continue with the core system components of the MAR systems. After that, we discuss advances in tracking and registration, since their functionality is crucial to any MAR application and the network connectivity of the devices that run MAR applications together with its importance to the performance of the application. We continue with the importance of data management in MAR systems and the systems performance and sustainability, and before we conclude this survey, we present existing challenging problems.},
	language = {en},
	urldate = {2019-08-22},
	journal = {IEEE Access},
	author = {Chatzopoulos, Dimitris and Bermejo, Carlos and Huang, Zhanpeng and Hui, Pan},
	year = {2017},
	pages = {6917--6950},
	file = {Chatzopoulos et al. - 2017 - Mobile Augmented Reality Survey From Where We Are.pdf:/home/ajk/Zotero/storage/7H78HKQF/Chatzopoulos et al. - 2017 - Mobile Augmented Reality Survey From Where We Are.pdf:application/pdf}
}

@inproceedings{huang_mobile_2012,
	address = {Taipei, Taiwan},
	title = {Mobile augmented reality based on cloud computing},
	isbn = {978-1-4673-2145-7 978-1-4673-2144-0 978-1-4673-2143-3},
	url = {http://ieeexplore.ieee.org/document/6325354/},
	doi = {10.1109/ICASID.2012.6325354},
	abstract = {In this paper, we implemented a mobile augmented reality system based on cloud computing. This system uses a mobile device with a camera to capture images of book spines and sends processed features to the cloud. In the cloud, the features are compared with the database and the information of the best matched book would be sent back to the mobile device. The information will then be rendered on the display via augmented reality. In order to reduce the transmission cost, the mobile device is used to perform most of the image processing tasks, such as the preprocessing, resizing, corner detection, and augmented reality rendering. On the other hand, the cloud is used to realize routine but large quantity feature comparisons. Using the cloud as the database also makes the future extension much more easily. For our prototype system, we use an Android smart phone as our mobile device, and Chunghwa Telecoms hicloud as the cloud.},
	language = {en},
	urldate = {2019-08-22},
	booktitle = {Anti-counterfeiting, {Security}, and {Identification}},
	publisher = {IEEE},
	author = {Huang, Bai-Ruei and Lin, Chang Hong and Lee, Chia-Han},
	month = aug,
	year = {2012},
	pages = {1--5},
	file = {Huang et al. - 2012 - Mobile augmented reality based on cloud computing.pdf:/home/ajk/Zotero/storage/DPGV8NAL/Huang et al. - 2012 - Mobile augmented reality based on cloud computing.pdf:application/pdf}
}

@inproceedings{liu_dare:_2018,
	address = {Cambridge},
	title = {{DARE}: {Dynamic} {Adaptive} {Mobile} {Augmented} {Reality} with {Edge} {Computing}},
	isbn = {978-1-5386-6043-0},
	shorttitle = {{DARE}},
	url = {https://ieeexplore.ieee.org/document/8526799/},
	doi = {10.1109/ICNP.2018.00011},
	abstract = {Mobile augmented reality (MAR) is a killer application of mobile edge computing because of its high computation demand and stringent latency requirement. Since edge networks and computing resources are highly dynamic, handling such dynamics is essential for providing high-quality MAR services. In this paper, we design a new network protocol named DARE (dynamic adaptive AR over the edge) that enables mobile users to dynamically change their AR conﬁgurations according to wireless channel conditions and computation workloads in edge servers. The dynamic conﬁguration adaptations reduce the service latency of MAR users and maximize the quality of augmentation (QoA) under varying network conditions and computation workloads. Considering the video frame size and computation model, i.e., object detection algorithms, as two key parameters in adapting the AR conﬁguration, we develop analytical models to characterize the impact of these parameters on QoA and the service latency. Then, we design optimization mechanisms on both the edge server and AR devices to guide the AR conﬁguration adaptation and server computation resource allocation. The performance of the DARE protocol is validated through a small-scale testbed implementation.},
	language = {en},
	urldate = {2019-08-22},
	booktitle = {2018 {IEEE} 26th {International} {Conference} on {Network} {Protocols} ({ICNP})},
	publisher = {IEEE},
	author = {Liu, Qiang and Han, Tao},
	month = sep,
	year = {2018},
	pages = {1--11},
	file = {Liu and Han - 2018 - DARE Dynamic Adaptive Mobile Augmented Reality wi.pdf:/home/ajk/Zotero/storage/9FXHMG58/Liu and Han - 2018 - DARE Dynamic Adaptive Mobile Augmented Reality wi.pdf:application/pdf}
}

@article{akherfi_mobile_2018,
	title = {Mobile cloud computing for computation offloading: {Issues} and challenges},
	volume = {14},
	issn = {22108327},
	shorttitle = {Mobile cloud computing for computation offloading},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2210832716300400},
	doi = {10.1016/j.aci.2016.11.002},
	abstract = {Despite the evolution and enhancements that mobile devices have experienced, they are still considered as limited computing devices. Today, users become more demanding and expect to execute computational intensive applications on their smartphone devices. Therefore, Mobile Cloud Computing (MCC) integrates mobile computing and Cloud Computing (CC) in order to extend capabilities of mobile devices using ofﬂoading techniques. Computation ofﬂoading tackles limitations of Smart Mobile Devices (SMDs) such as limited battery lifetime, limited processing capabilities, and limited storage capacity by ofﬂoading the execution and workload to other rich systems with better performance and resources. This paper presents the current ofﬂoading frameworks, computation ofﬂoading techniques, and analyzes them along with their main critical issues. In addition, it explores different important parameters based on which the frameworks are implemented such as ofﬂoading method and level of partitioning. Finally, it summarizes the issues in ofﬂoading frameworks in the MCC domain that requires further research.},
	language = {en},
	number = {1},
	urldate = {2019-08-22},
	journal = {Applied Computing and Informatics},
	author = {Akherfi, Khadija and Gerndt, Micheal and Harroud, Hamid},
	month = jan,
	year = {2018},
	pages = {1--16},
	file = {Akherfi et al. - 2018 - Mobile cloud computing for computation offloading.pdf:/home/ajk/Zotero/storage/RN9DKK9F/Akherfi et al. - 2018 - Mobile cloud computing for computation offloading.pdf:application/pdf}
}

@article{khan_survey_2014,
	title = {A {Survey} of {Mobile} {Cloud} {Computing} {Application} {Models}},
	volume = {16},
	issn = {1553-877X, 2373-745X},
	url = {https://ieeexplore.ieee.org/document/6553297/},
	doi = {10.1109/SURV.2013.062613.00160},
	abstract = {Smartphones are now capable of supporting a wide range of applications, many of which demand an ever increasing computational power. This poses a challenge because smartphones are resource-constrained devices with limited computation power, memory, storage, and energy. Fortunately, the cloud computing technology offers virtually unlimited dynamic resources for computation, storage, and service provision. Therefore, researchers envision extending cloud computing services to mobile devices to overcome the smartphones constraints. The challenge in doing so is that the traditional smartphone application models do not support the development of applications that can incorporate cloud computing features and requires specialized mobile cloud application models. This article presents mobile cloud architecture, ofﬂoading decision affecting entities, application models classiﬁcation, the latest mobile cloud application models, their critical analysis and future research directions.},
	language = {en},
	number = {1},
	urldate = {2019-08-22},
	journal = {IEEE Communications Surveys \& Tutorials},
	author = {Khan, Atta ur Rehman and Othman, Mazliza and Madani, Sajjad Ahmad and Khan, Samee Ullah},
	year = {2014},
	pages = {393--413},
	file = {Khan et al. - 2014 - A Survey of Mobile Cloud Computing Application Mod.pdf:/home/ajk/Zotero/storage/FP24FFN3/Khan et al. - 2014 - A Survey of Mobile Cloud Computing Application Mod.pdf:application/pdf}
}

@article{everingham_pascal_2010,
	title = {The {Pascal} {Visual} {Object} {Classes} ({VOC}) {Challenge}},
	volume = {88},
	issn = {0920-5691, 1573-1405},
	url = {http://link.springer.com/10.1007/s11263-009-0275-4},
	doi = {10.1007/s11263-009-0275-4},
	abstract = {The PASCAL Visual Object Classes (VOC) challenge is a benchmark in visual object category recognition and detection, providing the vision and machine learning communities with a standard dataset of images and annotation, and standard evaluation procedures. Organised annually from 2005 to present, the challenge and its associated dataset has become accepted as the benchmark for object detection.},
	language = {en},
	number = {2},
	urldate = {2019-08-22},
	journal = {International Journal of Computer Vision},
	author = {Everingham, Mark and Van Gool, Luc and Williams, Christopher K. I. and Winn, John and Zisserman, Andrew},
	month = jun,
	year = {2010},
	pages = {303--338},
	file = {Everingham et al. - 2010 - The Pascal Visual Object Classes (VOC) Challenge.pdf:/home/ajk/Zotero/storage/G7XLVEKC/Everingham et al. - 2010 - The Pascal Visual Object Classes (VOC) Challenge.pdf:application/pdf}
}

@article{zou_object_2019,
	title = {Object {Detection} in 20 {Years}: {A} {Survey}},
	shorttitle = {Object {Detection} in 20 {Years}},
	url = {http://arxiv.org/abs/1905.05055},
	abstract = {Object detection, as of one the most fundamental and challenging problems in computer vision, has received great attention in recent years. Its development in the past two decades can be regarded as an epitome of computer vision history. If we think of today’s object detection as a technical aesthetics under the power of deep learning, then turning back the clock 20 years we would witness the wisdom of cold weapon era. This paper extensively reviews 400+ papers of object detection in the light of its technical evolution, spanning over a quarter-century’s time (from the 1990s to 2019). A number of topics have been covered in this paper, including the milestone detectors in history, detection datasets, metrics, fundamental building blocks of the detection system, speed up techniques, and the recent state of the art detection methods. This paper also reviews some important detection applications, such as pedestrian detection, face detection, text detection, etc, and makes an in-deep analysis of their challenges as well as technical improvements in recent years.},
	language = {en},
	urldate = {2019-08-22},
	journal = {arXiv:1905.05055 [cs]},
	author = {Zou, Zhengxia and Shi, Zhenwei and Guo, Yuhong and Ye, Jieping},
	month = may,
	year = {2019},
	note = {arXiv: 1905.05055},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	annote = {Comment: This work has been submitted to the IEEE TPAMI for possible publication},
	file = {Zou et al. - 2019 - Object Detection in 20 Years A Survey.pdf:/home/ajk/Zotero/storage/GRTHFJJ8/Zou et al. - 2019 - Object Detection in 20 Years A Survey.pdf:application/pdf}
}

@inproceedings{redmon_you_2016,
	address = {Las Vegas, NV, USA},
	title = {You {Only} {Look} {Once}: {Unified}, {Real}-{Time} {Object} {Detection}},
	isbn = {978-1-4673-8851-1},
	shorttitle = {You {Only} {Look} {Once}},
	url = {http://ieeexplore.ieee.org/document/7780460/},
	doi = {10.1109/CVPR.2016.91},
	abstract = {We present YOLO, a new approach to object detection. Prior work on object detection repurposes classiﬁers to perform detection. Instead, we frame object detection as a regression problem to spatially separated bounding boxes and associated class probabilities. A single neural network predicts bounding boxes and class probabilities directly from full images in one evaluation. Since the whole detection pipeline is a single network, it can be optimized end-to-end directly on detection performance.},
	language = {en},
	urldate = {2019-08-22},
	booktitle = {2016 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	publisher = {IEEE},
	author = {Redmon, Joseph and Divvala, Santosh and Girshick, Ross and Farhadi, Ali},
	month = jun,
	year = {2016},
	pages = {779--788},
	file = {Redmon et al. - 2016 - You Only Look Once Unified, Real-Time Object Dete.pdf:/home/ajk/Zotero/storage/C5QM7YGV/Redmon et al. - 2016 - You Only Look Once Unified, Real-Time Object Dete.pdf:application/pdf}
}

@article{liu_ssd:_2016,
	title = {{SSD}: {Single} {Shot} {MultiBox} {Detector}},
	volume = {9905},
	shorttitle = {{SSD}},
	url = {http://arxiv.org/abs/1512.02325},
	doi = {10.1007/978-3-319-46448-0_2},
	abstract = {We present a method for detecting objects in images using a single deep neural network. Our approach, named SSD, discretizes the output space of bounding boxes into a set of default boxes over different aspect ratios and scales per feature map location. At prediction time, the network generates scores for the presence of each object category in each default box and produces adjustments to the box to better match the object shape. Additionally, the network combines predictions from multiple feature maps with different resolutions to naturally handle objects of various sizes. SSD is simple relative to methods that require object proposals because it completely eliminates proposal generation and subsequent pixel or feature resampling stages and encapsulates all computation in a single network. This makes SSD easy to train and straightforward to integrate into systems that require a detection component. Experimental results on the PASCAL VOC, COCO, and ILSVRC datasets conﬁrm that SSD has competitive accuracy to methods that utilize an additional object proposal step and is much faster, while providing a uniﬁed framework for both training and inference. For 300 × 300 input, SSD achieves 74.3\% mAP1 on VOC2007 test at 59 FPS on a Nvidia Titan X and for 512 × 512 input, SSD achieves 76.9\% mAP, outperforming a comparable state-of-the-art Faster R-CNN model. Compared to other single stage methods, SSD has much better accuracy even with a smaller input image size. Code is available at: https://github.com/weiliu89/caffe/tree/ssd .},
	language = {en},
	urldate = {2019-08-22},
	journal = {arXiv:1512.02325 [cs]},
	author = {Liu, Wei and Anguelov, Dragomir and Erhan, Dumitru and Szegedy, Christian and Reed, Scott and Fu, Cheng-Yang and Berg, Alexander C.},
	year = {2016},
	note = {arXiv: 1512.02325},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	pages = {21--37},
	annote = {Comment: ECCV 2016},
	file = {Liu et al. - 2016 - SSD Single Shot MultiBox Detector.pdf:/home/ajk/Zotero/storage/C94N3WCT/Liu et al. - 2016 - SSD Single Shot MultiBox Detector.pdf:application/pdf}
}

@article{sandler_mobilenetv2:_2018,
	title = {{MobileNetV}2: {Inverted} {Residuals} and {Linear} {Bottlenecks}},
	shorttitle = {{MobileNetV}2},
	url = {http://arxiv.org/abs/1801.04381},
	abstract = {In this paper we describe a new mobile architecture, MobileNetV2, that improves the state of the art performance of mobile models on multiple tasks and benchmarks as well as across a spectrum of different model sizes. We also describe efﬁcient ways of applying these mobile models to object detection in a novel framework we call SSDLite. Additionally, we demonstrate how to build mobile semantic segmentation models through a reduced form of DeepLabv3 which we call Mobile DeepLabv3.},
	language = {en},
	urldate = {2019-08-22},
	journal = {arXiv:1801.04381 [cs]},
	author = {Sandler, Mark and Howard, Andrew and Zhu, Menglong and Zhmoginov, Andrey and Chen, Liang-Chieh},
	month = jan,
	year = {2018},
	note = {arXiv: 1801.04381},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {Sandler et al. - 2018 - MobileNetV2 Inverted Residuals and Linear Bottlen.pdf:/home/ajk/Zotero/storage/DCUGD8XB/Sandler et al. - 2018 - MobileNetV2 Inverted Residuals and Linear Bottlen.pdf:application/pdf}
}

@article{dean_large_nodate,
	title = {Large {Scale} {Distributed} {Deep} {Networks}},
	abstract = {Recent work in unsupervised feature learning and deep learning has shown that being able to train large models can dramatically improve performance. In this paper, we consider the problem of training a deep network with billions of parameters using tens of thousands of CPU cores. We have developed a software framework called DistBelief that can utilize computing clusters with thousands of machines to train large models. Within this framework, we have developed two algorithms for large-scale distributed training: (i) Downpour SGD, an asynchronous stochastic gradient descent procedure supporting a large number of model replicas, and (ii) Sandblaster, a framework that supports a variety of distributed batch optimization procedures, including a distributed implementation of L-BFGS. Downpour SGD and Sandblaster L-BFGS both increase the scale and speed of deep network training. We have successfully used our system to train a deep network 30x larger than previously reported in the literature, and achieves state-of-the-art performance on ImageNet, a visual object recognition task with 16 million images and 21k categories. We show that these same techniques dramatically accelerate the training of a more modestly- sized deep network for a commercial speech recognition service. Although we focus on and report performance of these methods as applied to training large neural networks, the underlying algorithms are applicable to any gradient-based machine learning algorithm.},
	language = {en},
	author = {Dean, Jeffrey and Corrado, Greg and Monga, Rajat and Chen, Kai and Devin, Matthieu and Mao, Mark and Ranzato, Marc'aurelio and Senior, Andrew and Tucker, Paul and Yang, Ke and Le, Quoc V and Ng, Andrew Y},
	pages = {9},
	file = {Dean et al. - Large Scale Distributed Deep Networks.pdf:/home/ajk/Zotero/storage/2S2NKMFU/Dean et al. - Large Scale Distributed Deep Networks.pdf:application/pdf}
}

@inproceedings{teerapittayanon_distributed_2017,
	address = {Atlanta, GA, USA},
	title = {Distributed {Deep} {Neural} {Networks} {Over} the {Cloud}, the {Edge} and {End} {Devices}},
	isbn = {978-1-5386-1792-2},
	url = {http://ieeexplore.ieee.org/document/7979979/},
	doi = {10.1109/ICDCS.2017.226},
	abstract = {We propose distributed deep neural networks (DDNNs) over distributed computing hierarchies, consisting of the cloud, the edge (fog) and end devices. While being able to accommodate inference of a deep neural network (DNN) in the cloud, a DDNN also allows fast and localized inference using shallow portions of the neural network at the edge and end devices. When supported by a scalable distributed computing hierarchy, a DDNN can scale up in neural network size and scale out in geographical span. Due to its distributed nature, DDNNs enhance sensor fusion, system fault tolerance and data privacy for DNN applications. In implementing a DDNN, we map sections of a DNN onto a distributed computing hierarchy. By jointly training these sections, we minimize communication and resource usage for devices and maximize usefulness of extracted features which are utilized in the cloud. The resulting system has built-in support for automatic sensor fusion and fault tolerance. As a proof of concept, we show a DDNN can exploit geographical diversity of sensors to improve object recognition accuracy and reduce communication cost. In our experiment, compared with the traditional method of ofﬂoading raw sensor data to be processed in the cloud, DDNN locally processes most sensor data on end devices while achieving high accuracy and is able to reduce the communication cost by a factor of over 20x.},
	language = {en},
	urldate = {2019-08-22},
	booktitle = {2017 {IEEE} 37th {International} {Conference} on {Distributed} {Computing} {Systems} ({ICDCS})},
	publisher = {IEEE},
	author = {Teerapittayanon, Surat and McDanel, Bradley and Kung, H.T.},
	month = jun,
	year = {2017},
	pages = {328--339},
	file = {Teerapittayanon et al. - 2017 - Distributed Deep Neural Networks Over the Cloud, t.pdf:/home/ajk/Zotero/storage/A4QIEKK3/Teerapittayanon et al. - 2017 - Distributed Deep Neural Networks Over the Cloud, t.pdf:application/pdf}
}

@article{courbariaux_binaryconnect:_2015,
	title = {{BinaryConnect}: {Training} {Deep} {Neural} {Networks} with binary weights during propagations},
	shorttitle = {{BinaryConnect}},
	url = {http://arxiv.org/abs/1511.00363},
	abstract = {Deep Neural Networks (DNN) have achieved state-of-the-art results in a wide range of tasks, with the best results obtained with large training sets and large models. In the past, GPUs enabled these breakthroughs because of their greater computational speed. In the future, faster computation at both training and test time is likely to be crucial for further progress and for consumer applications on low-power devices. As a result, there is much interest in research and development of dedicated hardware for Deep Learning (DL). Binary weights, i.e., weights which are constrained to only two possible values (e.g. -1 or 1), would bring great beneﬁts to specialized DL hardware by replacing many multiply-accumulate operations by simple accumulations, as multipliers are the most space and powerhungry components of the digital implementation of neural networks. We introduce BinaryConnect, a method which consists in training a DNN with binary weights during the forward and backward propagations, while retaining precision of the stored weights in which gradients are accumulated. Like other dropout schemes, we show that BinaryConnect acts as regularizer and we obtain near state-of-the-art results with BinaryConnect on the permutation-invariant MNIST, CIFAR-10 and SVHN.},
	language = {en},
	urldate = {2019-08-22},
	journal = {arXiv:1511.00363 [cs]},
	author = {Courbariaux, Matthieu and Bengio, Yoshua and David, Jean-Pierre},
	month = nov,
	year = {2015},
	note = {arXiv: 1511.00363},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing},
	annote = {Comment: Accepted at NIPS 2015, 9 pages, 3 figures},
	file = {Courbariaux et al. - 2015 - BinaryConnect Training Deep Neural Networks with .pdf:/home/ajk/Zotero/storage/FPAS4UN2/Courbariaux et al. - 2015 - BinaryConnect Training Deep Neural Networks with .pdf:application/pdf}
}

@article{zhou_edge_2019,
	title = {Edge {Intelligence}: {Paving} the {Last} {Mile} of {Artificial} {Intelligence} {With} {Edge} {Computing}},
	volume = {107},
	issn = {0018-9219, 1558-2256},
	shorttitle = {Edge {Intelligence}},
	url = {https://ieeexplore.ieee.org/document/8736011/},
	doi = {10.1109/JPROC.2019.2918951},
	language = {en},
	number = {8},
	urldate = {2019-08-22},
	journal = {Proceedings of the IEEE},
	author = {Zhou, Zhi and Chen, Xu and Li, En and Zeng, Liekang and Luo, Ke and Zhang, Junshan},
	month = aug,
	year = {2019},
	pages = {1738--1762},
	annote = {Edge Intelligence
Related work
State-of-the-art},
	file = {Zhou et al. - 2019 - Edge Intelligence Paving the Last Mile of Artific.pdf:/home/ajk/Zotero/storage/UF4HPULQ/Zhou et al. - 2019 - Edge Intelligence Paving the Last Mile of Artific.pdf:application/pdf}
}

@article{mach_mobile_2017,
	title = {Mobile {Edge} {Computing}: {A} {Survey} on {Architecture} and {Computation} {Offloading}},
	volume = {19},
	issn = {1553-877X},
	shorttitle = {Mobile {Edge} {Computing}},
	url = {http://ieeexplore.ieee.org/document/7879258/},
	doi = {10.1109/COMST.2017.2682318},
	abstract = {Technological evolution of mobile user equipment (UEs), such as smartphones or laptops, goes hand-in-hand with evolution of new mobile applications. However, running computationally demanding applications at the UEs is constrained by limited battery capacity and energy consumption of the UEs. A suitable solution extending the battery life-time of the UEs is to ofﬂoad the applications demanding huge processing to a conventional centralized cloud. Nevertheless, this option introduces signiﬁcant execution delay consisting of delivery of the ofﬂoaded applications to the cloud and back plus time of the computation at the cloud. Such a delay is inconvenient and makes the ofﬂoading unsuitable for real-time applications. To cope with the delay problem, a new emerging concept, known as mobile edge computing (MEC), has been introduced. The MEC brings computation and storage resources to the edge of mobile network enabling it to run the highly demanding applications at the UE while meeting strict delay requirements. The MEC computing resources can be exploited also by operators and third parties for speciﬁc purposes. In this paper, we ﬁrst describe major use cases and reference scenarios where the MEC is applicable. After that we survey existing concepts integrating MEC functionalities to the mobile networks and discuss current advancement in standardization of the MEC. The core of this survey is, then, focused on user-oriented use case in the MEC, i.e., computation ofﬂoading. In this regard, we divide the research on computation ofﬂoading to three key areas: 1) decision on computation ofﬂoading; 2) allocation of computing resource within the MEC; and 3) mobility management. Finally, we highlight lessons learned in area of the MEC and we discuss open research challenges yet to be addressed in order to fully enjoy potentials offered by the MEC.},
	language = {en},
	number = {3},
	urldate = {2019-08-22},
	journal = {IEEE Communications Surveys \& Tutorials},
	author = {Mach, Pavel and Becvar, Zdenek},
	year = {2017},
	pages = {1628--1656},
	file = {Mach and Becvar - 2017 - Mobile Edge Computing A Survey on Architecture an.pdf:/home/ajk/Zotero/storage/DIDJK74Y/Mach and Becvar - 2017 - Mobile Edge Computing A Survey on Architecture an.pdf:application/pdf}
}

@inproceedings{liu_edge_2018,
	address = {Honolulu, HI},
	title = {An {Edge} {Network} {Orchestrator} for {Mobile} {Augmented} {Reality}},
	isbn = {978-1-5386-4128-6},
	url = {https://ieeexplore.ieee.org/document/8486241/},
	doi = {10.1109/INFOCOM.2018.8486241},
	abstract = {Mobile augmented reality (MAR) involves high complexity computation which cannot be performed efﬁciently on resource limited mobile devices. The performance of MAR would be signiﬁcantly improved by ofﬂoading the computation tasks to servers deployed with the close proximity to the users. In this paper, we design an edge network orchestrator to enable fast and accurate object analytics at the network edge for MAR. The measurement-based analytical models are built to characterize the tradeoff between the service latency and analytics accuracy in edge-based MAR systems. As a key component of the edge network orchestrator, a server assignment and frame resolution selection algorithm named FACT is proposed to mitigate the latency-accuracy tradeoff. Through network simulations, we evaluate the performance of the FACT algorithm and show the insights on optimizing the performance of edge-based MAR systems. We have implemented the edge network orchestrator and developed the corresponding communication protocol. Our experiments validate the performance of the proposed edge network orchestrator.},
	language = {en},
	urldate = {2019-08-22},
	booktitle = {{IEEE} {INFOCOM} 2018 - {IEEE} {Conference} on {Computer} {Communications}},
	publisher = {IEEE},
	author = {Liu, Qiang and Huang, Siqi and Opadere, Johnson and Han, Tao},
	month = apr,
	year = {2018},
	pages = {756--764},
	file = {Liu et al. - 2018 - An Edge Network Orchestrator for Mobile Augmented .pdf:/home/ajk/Zotero/storage/Q8K9S35Q/Liu et al. - 2018 - An Edge Network Orchestrator for Mobile Augmented .pdf:application/pdf}
}

@article{huang_distributed_2018,
	title = {Distributed {Deep} {Learning}-based {Offloading} for {Mobile} {Edge} {Computing} {Networks}},
	issn = {1383-469X, 1572-8153},
	url = {http://link.springer.com/10.1007/s11036-018-1177-x},
	doi = {10.1007/s11036-018-1177-x},
	abstract = {This paper studies mobile edge computing (MEC) networks where multiple wireless devices (WDs) choose to offload their computation tasks to an edge server. To conserve energy and maintain quality of service for WDs, the optimization of joint offloading decision and bandwidth allocation is formulated as a mixed integer programming problem. However, the problem is computationally limited by the curse of dimensionality, which cannot be solved by general optimization tools in an effective and efficient way, especially for large-scale WDs. In this paper, we propose a distributed deep learning-based offloading (DDLO) algorithm for MEC networks, where multiple parallel DNNs are used to generate offloading decisions. We adopt a shared replay memory to store newly generated offloading decisions which are further to train and improve all DNNs. Extensive numerical results show that the proposed DDLO algorithm can generate near-optimal offloading decisions in less than one second.},
	language = {en},
	urldate = {2019-08-22},
	journal = {Mobile Networks and Applications},
	author = {Huang, Liang and Feng, Xu and Feng, Anqi and Huang, Yupin and Qian, Li Ping},
	month = nov,
	year = {2018},
	file = {Huang et al. - 2018 - Distributed Deep Learning-based Offloading for Mob.pdf:/home/ajk/Zotero/storage/NHDB8GSQ/Huang et al. - 2018 - Distributed Deep Learning-based Offloading for Mob.pdf:application/pdf}
}

@article{shi_edge_2016,
	title = {Edge {Computing}: {Vision} and {Challenges}},
	volume = {3},
	issn = {2327-4662},
	shorttitle = {Edge {Computing}},
	url = {http://ieeexplore.ieee.org/document/7488250/},
	doi = {10.1109/JIOT.2016.2579198},
	abstract = {The proliferation of Internet of Things (IoT) and the success of rich cloud services have pushed the horizon of a new computing paradigm, edge computing, which calls for processing the data at the edge of the network. Edge computing has the potential to address the concerns of response time requirement, battery life constraint, bandwidth cost saving, as well as data safety and privacy. In this paper, we introduce the deﬁnition of edge computing, followed by several case studies, ranging from cloud ofﬂoading to smart home and city, as well as collaborative edge to materialize the concept of edge computing. Finally, we present several challenges and opportunities in the ﬁeld of edge computing, and hope this paper will gain attention from the community and inspire more research in this direction.},
	language = {en},
	number = {5},
	urldate = {2019-08-22},
	journal = {IEEE Internet of Things Journal},
	author = {Shi, Weisong and Cao, Jie and Zhang, Quan and Li, Youhuizi and Xu, Lanyu},
	month = oct,
	year = {2016},
	pages = {637--646},
	file = {Shi et al. - 2016 - Edge Computing Vision and Challenges.pdf:/home/ajk/Zotero/storage/QW5JS9YX/Shi et al. - 2016 - Edge Computing Vision and Challenges.pdf:application/pdf}
}

@inproceedings{yu_computation_2017,
	address = {Montreal, QC},
	title = {Computation offloading for mobile edge computing: {A} deep learning approach},
	isbn = {978-1-5386-3529-2 978-1-5386-3531-5},
	shorttitle = {Computation offloading for mobile edge computing},
	url = {http://ieeexplore.ieee.org/document/8292514/},
	doi = {10.1109/PIMRC.2017.8292514},
	abstract = {Computation ofﬂoading has already shown itself to be successful for enabling resource-intensive applications on mobile devices. Moreover, in view of mobile edge computing (MEC) system, mobile devices can ofﬂoad compute-intensive tasks to a nearby cloudlet, so as to save the energy and enhance the processing speed. However, due to the varying network conditions and limited computation resources of cloudlets, the ofﬂoading actions taken by a mobile user may not achieve the lowest cost. In this paper, we develop a dynamic ofﬂoading framework for mobile users, considering the local overhead in the mobile terminal side, as well as the limited communication and computation resources in the network side. We formulate the ofﬂoading decision problem as a multi-label classiﬁcation problem and develop the Deep Supervised Learning (DSL) method to minimize the computation and ofﬂoading overhead. Simulation results show that our proposal can reduce system cost up to 49.24\%, 23.87\%, 15.69\%, and 11.18\% compared to the “no ofﬂoading” scheme, “random ofﬂoading” scheme, “total ofﬂoading” scheme and “multi-label linear classiﬁerbased ofﬂoading” scheme, respectively.},
	language = {en},
	urldate = {2019-08-22},
	booktitle = {2017 {IEEE} 28th {Annual} {International} {Symposium} on {Personal}, {Indoor}, and {Mobile} {Radio} {Communications} ({PIMRC})},
	publisher = {IEEE},
	author = {Yu, Shuai and Wang, Xin and Langar, Rami},
	month = oct,
	year = {2017},
	pages = {1--6},
	file = {Yu et al. - 2017 - Computation offloading for mobile edge computing .pdf:/home/ajk/Zotero/storage/LHP3PAZM/Yu et al. - 2017 - Computation offloading for mobile edge computing .pdf:application/pdf}
}

@article{mao_survey_2017,
	title = {A {Survey} on {Mobile} {Edge} {Computing}: {The} {Communication} {Perspective}},
	volume = {19},
	issn = {1553-877X},
	shorttitle = {A {Survey} on {Mobile} {Edge} {Computing}},
	url = {http://ieeexplore.ieee.org/document/8016573/},
	doi = {10.1109/COMST.2017.2745201},
	abstract = {Driven by the visions of Internet of Things and 5G communications, recent years have seen a paradigm shift in mobile computing, from the centralized mobile cloud computing toward mobile edge computing (MEC). The main feature of MEC is to push mobile computing, network control and storage to the network edges (e.g., base stations and access points) so as to enable computation-intensive and latency-critical applications at the resource-limited mobile devices. MEC promises dramatic reduction in latency and mobile energy consumption, tackling the key challenges for materializing 5G vision. The promised gains of MEC have motivated extensive efforts in both academia and industry on developing the technology. A main thrust of MEC research is to seamlessly merge the two disciplines of wireless communications and mobile computing, resulting in a wide-range of new designs ranging from techniques for computation ofﬂoading to network architectures. This paper provides a comprehensive survey of the state-of-the-art MEC research with a focus on joint radio-and-computational resource management. We also discuss a set of issues, challenges, and future research directions for MEC research, including MEC system deployment, cache-enabled MEC, mobility management for MEC, green MEC, as well as privacy-aware MEC. Advancements in these directions will facilitate the transformation of MEC from theory to practice. Finally, we introduce recent standardization efforts on MEC as well as some typical MEC application scenarios.},
	language = {en},
	number = {4},
	urldate = {2019-08-22},
	journal = {IEEE Communications Surveys \& Tutorials},
	author = {Mao, Yuyi and You, Changsheng and Zhang, Jun and Huang, Kaibin and Letaief, Khaled B.},
	year = {2017},
	pages = {2322--2358},
	file = {Mao et al. - 2017 - A Survey on Mobile Edge Computing The Communicati.pdf:/home/ajk/Zotero/storage/YWHDJ5C4/Mao et al. - 2017 - A Survey on Mobile Edge Computing The Communicati.pdf:application/pdf}
}

@article{skala_scalable_2015,
	title = {Scalable {Distributed} {Computing} {Hierarchy}: {Cloud}, {Fog} and {Dew} {Computing}},
	volume = {2},
	abstract = {The paper considers the conceptual approach for organization of the vertical hierarchical links between the scalable distributed computing paradigms: Cloud Computing, Fog Computing and Dew Computing. In this paper, the Dew Computing is described and recognized as a new structural layer in the existing distributed computing hierarchy. In the existing computing hierarchy, the Dew computing is positioned as the ground level for the Cloud and Fog computing paradigms. Vertical, complementary, hierarchical division from Cloud to Dew Computing satisﬁes the needs of high- and low-end computing demands in everyday life and work. These new computing paradigms lower the cost and improve the performance, particularly for concepts and applications such as the Internet of Things (IoT) and the Internet of Everything (IoE). In addition, the Dew computing paradigm will require new programming models that will efﬁciently reduce the complexity and improve the productivity and usability of scalable distributed computing, following the principles of High-Productivity computing.},
	language = {en},
	number = {1},
	author = {Skala, Karolj and Davidovic, Davor and Afgan, Enis and Sovic, Ivan},
	year = {2015},
	pages = {9},
	annote = {Main work for the thesis},
	file = {Skala et al. - 2015 - Scalable Distributed Computing Hierarchy Cloud, F.pdf:/home/ajk/Zotero/storage/7BCBE8R2/Skala et al. - 2015 - Scalable Distributed Computing Hierarchy Cloud, F.pdf:application/pdf}
}

@article{song_collaborative_nodate,
	title = {Collaborative {Learning} for {Deep} {Neural} {Networks}},
	abstract = {We introduce collaborative learning in which multiple classiﬁer heads of the same network are simultaneously trained on the same training data to improve generalization and robustness to label noise with no extra inference cost. It acquires the strengths from auxiliary training, multi-task learning and knowledge distillation. There are two important mechanisms involved in collaborative learning. First, the consensus of multiple views from different classiﬁer heads on the same example provides supplementary information as well as regularization to each classiﬁer, thereby improving generalization. Second, intermediate-level representation (ILR) sharing with backpropagation rescaling aggregates the gradient ﬂows from all heads, which not only reduces training computational complexity, but also facilitates supervision to the shared layers. The empirical results on CIFAR and ImageNet datasets demonstrate that deep neural networks learned as a group in a collaborative way signiﬁcantly reduce the generalization error and increase the robustness to label noise.},
	language = {en},
	author = {Song, Guocong and Chai, Wei},
	pages = {10},
	file = {Song and Chai - Collaborative Learning for Deep Neural Networks.pdf:/home/ajk/Zotero/storage/86GVGZSM/Song and Chai - Collaborative Learning for Deep Neural Networks.pdf:application/pdf}
}

@article{song_collaborative_2018,
	title = {Collaborative {Learning} for {Deep} {Neural} {Networks}},
	url = {http://arxiv.org/abs/1805.11761},
	abstract = {We introduce collaborative learning in which multiple classiﬁer heads of the same network are simultaneously trained on the same training data to improve generalization and robustness to label noise with no extra inference cost. It acquires the strengths from auxiliary training, multi-task learning and knowledge distillation. There are two important mechanisms involved in collaborative learning. First, the consensus of multiple views from different classiﬁer heads on the same example provides supplementary information as well as regularization to each classiﬁer, thereby improving generalization. Second, intermediate-level representation (ILR) sharing with backpropagation rescaling aggregates the gradient ﬂows from all heads, which not only reduces training computational complexity, but also facilitates supervision to the shared layers. The empirical results on CIFAR and ImageNet datasets demonstrate that deep neural networks learned as a group in a collaborative way signiﬁcantly reduce the generalization error and increase the robustness to label noise.},
	language = {en},
	urldate = {2019-08-26},
	journal = {arXiv:1805.11761 [cs, stat]},
	author = {Song, Guocong and Chai, Wei},
	month = may,
	year = {2018},
	note = {arXiv: 1805.11761},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: To appear in NIPS 2018},
	file = {Song and Chai - 2018 - Collaborative Learning for Deep Neural Networks.pdf:/home/ajk/Zotero/storage/WUJEKLUH/Song and Chai - 2018 - Collaborative Learning for Deep Neural Networks.pdf:application/pdf}
}

@article{eshratifar_bottlenet:_2019,
	title = {{BottleNet}: {A} {Deep} {Learning} {Architecture} for {Intelligent} {Mobile} {Cloud} {Computing} {Services}},
	shorttitle = {{BottleNet}},
	url = {http://arxiv.org/abs/1902.01000},
	abstract = {Recent studies have shown the latency and energy consumption of deep neural networks can be significantly improved by splitting the network between the mobile device and cloud. This paper introduces a new deep learning architecture, called BottleNet, for reducing the feature size needed to be sent to the cloud. Furthermore, we propose a training method for compensating for the potential accuracy loss due to the lossy compression of features before transmitting them to the cloud. BottleNet achieves on average 30× improvement in end-to-end latency and 40× improvement in mobile energy consumption compared to the cloud-only approach with negligible accuracy loss.},
	language = {en},
	urldate = {2019-08-26},
	journal = {arXiv:1902.01000 [cs]},
	author = {Eshratifar, Amir Erfan and Esmaili, Amirhossein and Pedram, Massoud},
	month = feb,
	year = {2019},
	note = {arXiv: 1902.01000},
	keywords = {Computer Science - Machine Learning, Computer Science - Distributed, Parallel, and Cluster Computing},
	annote = {Comment: arXiv admin note: text overlap with arXiv:1902.00147},
	file = {Eshratifar et al. - 2019 - BottleNet A Deep Learning Architecture for Intell.pdf:/home/ajk/Zotero/storage/VA7BJQTM/Eshratifar et al. - 2019 - BottleNet A Deep Learning Architecture for Intell.pdf:application/pdf}
}

@inproceedings{teerapittayanon_branchynet:_2016,
	address = {Cancun},
	title = {{BranchyNet}: {Fast} inference via early exiting from deep neural networks},
	isbn = {978-1-5090-4847-2},
	shorttitle = {{BranchyNet}},
	url = {http://ieeexplore.ieee.org/document/7900006/},
	doi = {10.1109/ICPR.2016.7900006},
	abstract = {Deep neural networks are state of the art methods for many learning tasks due to their ability to extract increasingly better features at each network layer. However, the improved performance of additional layers in a deep network comes at the cost of added latency and energy usage in feedforward inference. As networks continue to get deeper and larger, these costs become more prohibitive for real-time and energy-sensitive applications. To address this issue, we present BranchyNet, a novel deep network architecture that is augmented with additional side branch classiﬁers. The architecture allows prediction results for a large portion of test samples to exit the network early via these branches when samples can already be inferred with high conﬁdence. BranchyNet exploits the observation that features learned at an early layer of a network may often be sufﬁcient for the classiﬁcation of many data points. For more difﬁcult samples, which are expected less frequently, BranchyNet will use further or all network layers to provide the best likelihood of correct prediction. We study the BranchyNet architecture using several well-known networks (LeNet, AlexNet, ResNet) and datasets (MNIST, CIFAR10) and show that it can both improve accuracy and signiﬁcantly reduce the inference time of the network.},
	language = {en},
	urldate = {2019-08-26},
	booktitle = {2016 23rd {International} {Conference} on {Pattern} {Recognition} ({ICPR})},
	publisher = {IEEE},
	author = {Teerapittayanon, Surat and McDanel, Bradley and Kung, H.T.},
	month = dec,
	year = {2016},
	pages = {2464--2469},
	file = {Teerapittayanon et al. - 2016 - BranchyNet Fast inference via early exiting from .pdf:/home/ajk/Zotero/storage/SDJSRV5Z/Teerapittayanon et al. - 2016 - BranchyNet Fast inference via early exiting from .pdf:application/pdf}
}

@inproceedings{teerapittayanon_distributed_2017-1,
	address = {Atlanta, GA, USA},
	title = {Distributed {Deep} {Neural} {Networks} {Over} the {Cloud}, the {Edge} and {End} {Devices}},
	isbn = {978-1-5386-1792-2},
	url = {http://ieeexplore.ieee.org/document/7979979/},
	doi = {10.1109/ICDCS.2017.226},
	abstract = {We propose distributed deep neural networks (DDNNs) over distributed computing hierarchies, consisting of the cloud, the edge (fog) and end devices. While being able to accommodate inference of a deep neural network (DNN) in the cloud, a DDNN also allows fast and localized inference using shallow portions of the neural network at the edge and end devices. When supported by a scalable distributed computing hierarchy, a DDNN can scale up in neural network size and scale out in geographical span. Due to its distributed nature, DDNNs enhance sensor fusion, system fault tolerance and data privacy for DNN applications. In implementing a DDNN, we map sections of a DNN onto a distributed computing hierarchy. By jointly training these sections, we minimize communication and resource usage for devices and maximize usefulness of extracted features which are utilized in the cloud. The resulting system has built-in support for automatic sensor fusion and fault tolerance. As a proof of concept, we show a DDNN can exploit geographical diversity of sensors to improve object recognition accuracy and reduce communication cost. In our experiment, compared with the traditional method of ofﬂoading raw sensor data to be processed in the cloud, DDNN locally processes most sensor data on end devices while achieving high accuracy and is able to reduce the communication cost by a factor of over 20x.},
	language = {en},
	urldate = {2019-08-26},
	booktitle = {2017 {IEEE} 37th {International} {Conference} on {Distributed} {Computing} {Systems} ({ICDCS})},
	publisher = {IEEE},
	author = {Teerapittayanon, Surat and McDanel, Bradley and Kung, H.T.},
	month = jun,
	year = {2017},
	pages = {328--339},
	file = {Teerapittayanon et al. - 2017 - Distributed Deep Neural Networks Over the Cloud, t.pdf:/home/ajk/Zotero/storage/4HWB62A9/Teerapittayanon et al. - 2017 - Distributed Deep Neural Networks Over the Cloud, t.pdf:application/pdf}
}

@article{stoica_berkeley_2017,
	title = {A {Berkeley} {View} of {Systems} {Challenges} for {AI}},
	url = {http://arxiv.org/abs/1712.05855},
	abstract = {With the increasing commoditization of computer vision, speech recognition and machine translation systems and the widespread deployment of learning-based back-end technologies such as digital advertising and intelligent infrastructures, AI (Arti cial Intelligence) has moved from research labs to production. ese changes have been made possible by unprecedented levels of data and computation, by methodological advances in machine learning, by innovations in systems so ware and architectures, and by the broad accessibility of these technologies.},
	language = {en},
	urldate = {2019-09-02},
	journal = {arXiv:1712.05855 [cs]},
	author = {Stoica, Ion and Song, Dawn and Popa, Raluca Ada and Patterson, David and Mahoney, Michael W. and Katz, Randy and Joseph, Anthony D. and Jordan, Michael and Hellerstein, Joseph M. and Gonzalez, Joseph E. and Goldberg, Ken and Ghodsi, Ali and Culler, David and Abbeel, Pieter},
	month = dec,
	year = {2017},
	note = {arXiv: 1712.05855},
	keywords = {Computer Science - Artificial Intelligence},
	annote = {Comment: Berkeley Technical Report},
	file = {Stoica et al. - 2017 - A Berkeley View of Systems Challenges for AI.pdf:/home/ajk/Zotero/storage/XWTWHH3J/Stoica et al. - 2017 - A Berkeley View of Systems Challenges for AI.pdf:application/pdf}
}

@article{he_deep_2015,
	title = {Deep {Residual} {Learning} for {Image} {Recognition}},
	url = {http://arxiv.org/abs/1512.03385},
	abstract = {Deeper neural networks are more difﬁcult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers—8× deeper than VGG nets [41] but still having lower complexity. An ensemble of these residual nets achieves 3.57\% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classiﬁcation task. We also present analysis on CIFAR-10 with 100 and 1000 layers.},
	language = {en},
	urldate = {2019-09-04},
	journal = {arXiv:1512.03385 [cs]},
	author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	month = dec,
	year = {2015},
	note = {arXiv: 1512.03385},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	annote = {Comment: Tech report},
	file = {He et al. - 2015 - Deep Residual Learning for Image Recognition.pdf:/home/ajk/Zotero/storage/ZLU3X59T/He et al. - 2015 - Deep Residual Learning for Image Recognition.pdf:application/pdf}
}

@article{yosinski_how_2014,
	title = {How transferable are features in deep neural networks?},
	url = {http://arxiv.org/abs/1411.1792},
	abstract = {Many deep neural networks trained on natural images exhibit a curious phenomenon in common: on the ﬁrst layer they learn features similar to Gabor ﬁlters and color blobs. Such ﬁrst-layer features appear not to be speciﬁc to a particular dataset or task, but general in that they are applicable to many datasets and tasks. Features must eventually transition from general to speciﬁc by the last layer of the network, but this transition has not been studied extensively. In this paper we experimentally quantify the generality versus speciﬁcity of neurons in each layer of a deep convolutional neural network and report a few surprising results. Transferability is negatively affected by two distinct issues: (1) the specialization of higher layer neurons to their original task at the expense of performance on the target task, which was expected, and (2) optimization difﬁculties related to splitting networks between co-adapted neurons, which was not expected. In an example network trained on ImageNet, we demonstrate that either of these two issues may dominate, depending on whether features are transferred from the bottom, middle, or top of the network. We also document that the transferability of features decreases as the distance between the base task and target task increases, but that transferring features even from distant tasks can be better than using random features. A ﬁnal surprising result is that initializing a network with transferred features from almost any number of layers can produce a boost to generalization that lingers even after ﬁne-tuning to the target dataset.},
	language = {en},
	urldate = {2019-09-16},
	journal = {arXiv:1411.1792 [cs]},
	author = {Yosinski, Jason and Clune, Jeff and Bengio, Yoshua and Lipson, Hod},
	month = nov,
	year = {2014},
	note = {arXiv: 1411.1792},
	keywords = {Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing},
	annote = {Comment: To appear in Advances in Neural Information Processing Systems 27 (NIPS 2014)},
	file = {Yosinski et al. - 2014 - How transferable are features in deep neural netwo.pdf:/home/ajk/Zotero/storage/JIFRNQES/Yosinski et al. - 2014 - How transferable are features in deep neural netwo.pdf:application/pdf}
}

@article{masters_revisiting_nodate,
	title = {Revisiting {Small} {Batch} {Training} for {Deep} {Neural} {Networks}},
	volume = {abs/1804.07612},
	url = {http://arxiv.org/abs/1804.07612},
	urldate = {2018-08-13},
	author = {Masters, Dominic and Luschi, Carlos},
	file = {1804.07612.pdf:/home/ajk/Zotero/storage/RMHUUJQ3/1804.07612.pdf:application/pdf}
}

@inproceedings{noauthor_notitle_nodate
}

@inproceedings{deng_imagenet:_2009,
	title = {{ImageNet}: {A} {Large}-{Scale} {Hierarchical} {Image} {Database}},
	booktitle = {{CVPR}09},
	author = {Deng, J. and Dong, W. and Socher, R. and Li, L.-J. and Li, K. and Fei-Fei, L.},
	year = {2009}
}