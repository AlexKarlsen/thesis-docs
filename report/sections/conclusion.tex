\hypertarget{conclusion}{%
\chapter{Conclusion}\label{ch:conclusion}}
%\thispagestyle{fancy}


In conclusion, early exit \gls{dnn}s are shown to be a powerful tool to handle the accuracy-latency trade-off necessary for time-critical applications. Only a small number of samples actually require extremely deep models and can, with high confidence, exit the model earlier. We show that models with densely connected layers are more suitable for early exit models, e.g., \gls{bdensenet} and \gls{msdnet}, as they obtain a higher accuracy for early exits. However, the \gls{bresnet} achieves higher reliability on \gls{gpu}-enabled platforms. Even though the early exits of the \gls{bresnet} have the lowest accuracy, it is compensated by a higher end-accuracy with faster runtime, i.e., it is able to provide higher reliability at lower delay thresholds.

Our inference scheme \gls{aee} improves the reliability under stringent deadlines using early exit \gls{dnn}s. The scheme can be used for both local inference and remote offloading. Offloading for edge inference shows improvements over local execution for most models. The adaptability of the best-effort scheme handles latency uncertainties from computation and communication delays. It enables service for time-critical applications in time ranges where it is not possible with the conventional \gls{dnn}s. In many \gls{iot} applications, the end \gls{iot} devices are not able to run the \gls{dnn}s, therefore edge offloading is a must. The \gls{nuc} used in the experiments is a much more powerful device than standard \gls{iot} devices. Our results reveal that no single model outperforms other models in all delay conditions. This calls for model selection, depending on hardware platforms, connectivity, and application deadlines. Our analysis of combining prediction from subsequent exits gave no significant improvements and showed that using the deepest available exit is always the best option.

%\hypertarget{futurework}{%
%	\chapter{Future Work}\label{ch:futurework}}
%%\thispagestyle{fancy}

