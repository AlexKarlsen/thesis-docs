\hypertarget{inroduction}{%
\addchap{Introduction}\label{sec:introduction}}
\thispagestyle{fancy}

The emerging applications, such as AR/VR, autonomous driving, mission critical IoT applications, and others, require extreme low latency of AI decision feedback. The conventional approach is sending the sensor data, e.g., images,
to the central cloud or data center to perform advanced ML algorithms and send the results, e.g., object detection, classification, back to the end mobile devices. The conventional cloud-centric ML framework cannot fulfill the stringent requirements of these emerging applications. Mobile Edge computing is a new computing paradigm which brings the computing units from the core of
the network to the network edge. MEC has many benefits such as lower communication latency, higher reliability and resiliency, better security and privacy, scalability and context-awareness and others. The objective of this thesis is, taking mobile AR applications as use case, to design and implement of MEC offloading deep learning algorithms to maximize the inference reliability while meeting the service latency deadline. The thesis will design feasible offloading schemes, such as deep neural network partitioning, preprosssing (feature extractions), in objective detection and classification. The proposed schemes will be implemented using Raspberry Pi and Jetson TX2. The communication and computation latency, as well as the inference accuracy and reliability will be measured and analyzed.

%Recent years breakthrough within \gls{dl} have led to a dramatic increase in the amount of \gls{ai} applications and services, such as personal assistants, recommendation systems and surveillance systems. Combined with the development of mobile computing and \gls{iot}, where billions of device are getting connected to the internet. Traditionally data for \gls{ai} applications and services are generated by the devices and transferred to large data centers for computation.    To fully unleash the power of \gls{ai} applications and services \gls{ei} or edge \gls{ai} have become an interesting research area. \gls{ei} have potential to reduce the 